# src/main.py
import cv2
import time
import datetime
import os
import gc
import sys
import platform
import threading
import logging

# --- C·∫§U H√åNH LOGGING ---
# Log ra file tr√™n Pi ƒë·ªÉ debug t·ª´ xa
IS_WINDOWS_EARLY = platform.system() == "Windows"
if not IS_WINDOWS_EARLY:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('attendance.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
else:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )

logger = logging.getLogger(__name__)

# Support both direct script execution and module import
try:
    from .detect import detect_faces
    from .recognition import FaceRecognizer
    from .database import (log_attendance, add_employee, remove_employee, 
                           sync_employees_with_face_db, init_db,
                           midnight_checkout_all_sessions)
    from .config import CONFIG
except ImportError:
    from detect import detect_faces
    from recognition import FaceRecognizer
    from database import (log_attendance, add_employee, remove_employee, 
                          sync_employees_with_face_db, init_db,
                          midnight_checkout_all_sessions)
    from config import CONFIG

# --- T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN PLATFORM ---
IS_WINDOWS = platform.system() == "Windows"
IS_PI = platform.system() == "Linux" and os.path.exists("/proc/device-tree/model")

# --- C·∫§U H√åNH ---
# C√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë∆∞·ª£c l·∫•y t·ª´ 'config/config.json' qua module `src/config.py` (CONFIG dict)
COOLDOWN_SECONDS = int(CONFIG.get('COOLDOWN_SECONDS', 300))  # seconds
HOLD_TIME_SECONDS = float(CONFIG.get('HOLD_TIME_SECONDS', 1.5))  # seconds
ENABLE_WEB_SERVER = bool(CONFIG.get('ENABLE_WEB_SERVER', True))
WEB_PORT = int(CONFIG.get('WEB_PORT', 5000))
ENABLE_ANTISPOOF = bool(CONFIG.get('ENABLE_ANTISPOOF', False))

# Threshold cho recognition:
RECOGNITION_THRESHOLD = float(CONFIG.get('RECOGNITION_THRESHOLD', 0.55))

# --- CH·∫æ ƒê·ªò HI·ªÇN TH·ªä (GUI) ---
# FORCE_GUI_MODE: B·∫≠t n√†y ƒë·ªÉ hi·ªÉn th·ªã c·ª≠a s·ªï camera tr√™n Pi (k·∫øt n·ªëi m√†n h√¨nh HDMI)
FORCE_GUI_MODE = bool(CONFIG.get('FORCE_GUI_MODE', False))  # ƒê·∫∑t True khi mu·ªën debug tr√™n Pi v·ªõi m√†n h√¨nh

# Ch·∫ø ƒë·ªô ho·∫°t ƒë·ªông: Windows lu√¥n c√≥ GUI, Pi m·∫∑c ƒë·ªãnh headless (tr·ª´ khi FORCE_GUI)
HEADLESS_MODE = not IS_WINDOWS and not FORCE_GUI_MODE

# --- C·∫§U H√åNH AUTO CHECK-OUT L√öC N·ª¨A ƒê√äM ---
# T·ª± ƒë·ªông check-out t·∫•t c·∫£ sessions ƒëang m·ªü v√†o l√∫c 00:00 m·ªói ng√†y
ENABLE_MIDNIGHT_CHECKOUT = bool(CONFIG.get('ENABLE_MIDNIGHT_CHECKOUT', True))

# --- C·∫§U H√åNH T·ªêI ∆ØU RAM (cho Pi 3) ---
LOW_MEMORY_MODE = bool(CONFIG.get('LOW_MEMORY_MODE', IS_PI))  # T·ª± ƒë·ªông b·∫≠t tr√™n Pi (c√≥ th·ªÉ override t·ª´ file config)
CAMERA_WIDTH = int(CONFIG.get('CAMERA_WIDTH', 640 if not LOW_MEMORY_MODE else 320))
CAMERA_HEIGHT = int(CONFIG.get('CAMERA_HEIGHT', 480 if not LOW_MEMORY_MODE else 240))
GC_INTERVAL = int(CONFIG.get('GC_INTERVAL', 30))

# --- ADAPTIVE FRAME SKIP ---
# T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh s·ªë frame b·ªè qua d·ª±a tr√™n t·∫£i CPU
ENABLE_ADAPTIVE_SKIP = bool(CONFIG.get('ENABLE_ADAPTIVE_SKIP', IS_PI))  # Ch·ªâ b·∫≠t tr√™n Pi
TARGET_PROCESS_TIME = float(CONFIG.get('TARGET_PROCESS_TIME', 0.15))  # M·ª•c ti√™u: x·ª≠ l√Ω m·ªói frame trong 150ms
MIN_FRAME_SKIP = int(CONFIG.get('MIN_FRAME_SKIP', 1))
MAX_FRAME_SKIP = int(CONFIG.get('MAX_FRAME_SKIP', 5))
DEFAULT_FRAME_SKIP = int(CONFIG.get('DEFAULT_FRAME_SKIP', 2 if IS_PI else 1))


class AdaptiveFrameSkip:
    """
    T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh frame skip d·ª±a tr√™n th·ªùi gian x·ª≠ l√Ω th·ª±c t·∫ø.
    - CPU nh√†n r·ªói ‚Üí gi·∫£m skip (x·ª≠ l√Ω nhi·ªÅu frame h∆°n, m∆∞·ª£t h∆°n)
    - CPU qu√° t·∫£i ‚Üí tƒÉng skip (gi·∫£m t·∫£i, tr√°nh lag)
    """
    def __init__(self, target_time=TARGET_PROCESS_TIME, 
                 min_skip=MIN_FRAME_SKIP, max_skip=MAX_FRAME_SKIP,
                 initial_skip=DEFAULT_FRAME_SKIP):
        self.target_time = target_time
        self.min_skip = min_skip
        self.max_skip = max_skip
        self.current_skip = initial_skip
        
        # Smoothing: d√πng moving average ƒë·ªÉ tr√°nh dao ƒë·ªông
        self.time_history = []
        self.history_size = 5
        
        # Stats
        self.total_frames = 0
        self.processed_frames = 0
        self.last_adjust_time = time.time()
        self.adjust_interval = 2.0  # ƒêi·ªÅu ch·ªânh m·ªói 2 gi√¢y
    
    def update(self, process_time):
        """
        C·∫≠p nh·∫≠t th·ªùi gian x·ª≠ l√Ω v√† ƒëi·ªÅu ch·ªânh skip rate.
        
        Args:
            process_time: Th·ªùi gian x·ª≠ l√Ω frame v·ª´a r·ªìi (gi√¢y)
        """
        self.time_history.append(process_time)
        if len(self.time_history) > self.history_size:
            self.time_history.pop(0)
        
        self.processed_frames += 1
        
        # Ch·ªâ ƒëi·ªÅu ch·ªânh m·ªói adjust_interval gi√¢y
        current_time = time.time()
        if current_time - self.last_adjust_time < self.adjust_interval:
            return self.current_skip
        
        self.last_adjust_time = current_time
        
        # T√≠nh trung b√¨nh th·ªùi gian x·ª≠ l√Ω
        avg_time = sum(self.time_history) / len(self.time_history)
        
        old_skip = self.current_skip
        
        # ƒêi·ªÅu ch·ªânh skip d·ª±a tr√™n t·ªâ l·ªá v·ªõi target
        if avg_time < self.target_time * 0.5:
            # CPU r·∫•t nh√†n r·ªói (<75ms) ‚Üí gi·∫£m skip nhi·ªÅu
            self.current_skip = max(self.min_skip, self.current_skip - 1)
        elif avg_time < self.target_time * 0.8:
            # CPU nh√†n r·ªói (<120ms) ‚Üí gi·∫£m skip nh·∫π
            if self.current_skip > self.min_skip:
                self.current_skip -= 1
        elif avg_time > self.target_time * 1.5:
            # CPU qu√° t·∫£i (>225ms) ‚Üí tƒÉng skip nhi·ªÅu
            self.current_skip = min(self.max_skip, self.current_skip + 2)
        elif avg_time > self.target_time * 1.2:
            # CPU h∆°i cao (>180ms) ‚Üí tƒÉng skip nh·∫π
            self.current_skip = min(self.max_skip, self.current_skip + 1)
        
        # Log khi thay ƒë·ªïi
        if old_skip != self.current_skip:
            logger.debug(f"Adaptive skip: {old_skip} ‚Üí {self.current_skip} (avg={avg_time*1000:.0f}ms)")
        
        return self.current_skip
    
    def should_process(self, frame_count):
        """
        Ki·ªÉm tra frame n√†y c√≥ n√™n x·ª≠ l√Ω kh√¥ng.
        
        Returns:
            True n·∫øu n√™n x·ª≠ l√Ω frame n√†y
        """
        self.total_frames += 1
        return frame_count % self.current_skip == 0
    
    def get_stats(self):
        """L·∫•y th·ªëng k√™ hi·ªáu su·∫•t"""
        if self.total_frames == 0:
            return "No stats yet"
        
        avg_time = sum(self.time_history) / len(self.time_history) if self.time_history else 0
        skip_rate = (self.total_frames - self.processed_frames) / self.total_frames * 100
        
        return {
            'current_skip': self.current_skip,
            'avg_process_ms': avg_time * 1000,
            'skip_rate_percent': skip_rate,
            'effective_fps': self.processed_frames / max(1, self.total_frames) * 15  # Gi·∫£ s·ª≠ camera 15fps
        }

def start_web_server():
    """Ch·∫°y web server trong thread ri√™ng"""
    try:
        from web_server import run_server
        run_server(host='0.0.0.0', port=WEB_PORT)
    except Exception:
        pass  # L·ªói web server kh√¥ng ·∫£nh h∆∞·ªüng ch·∫•m c√¥ng ch√≠nh

def init_camera(max_retries=3, retry_delay=2):
    """Kh·ªüi t·∫°o camera v·ªõi retry logic"""
    for attempt in range(max_retries):
        cap = cv2.VideoCapture(0)
        if cap.isOpened():
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            # Th√™m c·∫•u h√¨nh cho Pi camera
            if IS_PI:
                cap.set(cv2.CAP_PROP_FPS, 15)  # Gi·∫£m FPS ƒë·ªÉ ·ªïn ƒë·ªãnh
                cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
            # Warm-up camera - ƒë·ªçc v√†i frame ƒë·∫ßu ƒë·ªÉ ·ªïn ƒë·ªãnh
            for _ in range(5):
                cap.grab()
            return cap
        
        print(f"‚ö†Ô∏è Camera kh√¥ng s·∫µn s√†ng, th·ª≠ l·∫°i ({attempt + 1}/{max_retries})...")
        time.sleep(retry_delay)
    
    return None

def main():
    # 0. Kh·ªüi t·∫°o Database
    init_db()
    
    # 0.1 Kh·ªüi ƒë·ªông Web Server (ch·∫°y n·ªÅn)
    if ENABLE_WEB_SERVER:
        web_thread = threading.Thread(target=start_web_server, daemon=True)
        web_thread.start()
    
    # 1. Kh·ªüi t·∫°o Camera v·ªõi retry
    cap = init_camera()
    if cap is None:
        print("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi camera sau nhi·ªÅu l·∫ßn th·ª≠!")
        return

    try:
        # Lazy loading: Ch·ªâ load AntiSpoof n·∫øu c·∫ßn
        anti = None
        if ENABLE_ANTISPOOF:
            try:
                from .antispoof import AntiSpoof
            except ImportError:
                from antispoof import AntiSpoof
            anti = AntiSpoof()
        
        recognizer = FaceRecognizer()
        
        # ƒê·ªìng b·ªô SQLite employees v·ªõi face_db.pkl
        sync_result = sync_employees_with_face_db(recognizer.get_registered_names())
        
        # Garbage collect sau khi load xong models
        gc.collect()
        
    except Exception as e:
        logger.error(f"L·ªói kh·ªüi t·∫°o: {e}")
        return

    # Dictionary l∆∞u th·ªùi gian ch·∫•m c√¥ng g·∫ßn nh·∫•t
    last_checkin = {} 
    face_hold_tracker = {}

    # --- LOG KH·ªûI ƒê·ªòNG G·ªåN G√ÄNG ---
    print("\n" + "="*50)
    print("üïê H·ªÜ TH·ªêNG CH·∫§M C√îNG")
    print("="*50)
    
    # Hi·ªÉn th·ªã mode chi ti·∫øt h∆°n
    if IS_WINDOWS:
        mode = "Windows (GUI)"
    elif FORCE_GUI_MODE:
        mode = "Pi (GUI - debug mode)"
    else:
        mode = "Pi (Headless)"
    
    n_people, n_emb = recognizer.get_db_info()
    print(f"üìç Mode: {mode}")
    print(f"üë• Database: {n_people} ng∆∞·ªùi ({n_emb} ·∫£nh)")
    print(f"‚è±Ô∏è Cooldown: {COOLDOWN_SECONDS}s ({COOLDOWN_SECONDS//60}m)")
    
    if sync_result['added'] or sync_result['removed']:
        print(f"üîÑ Sync: +{sync_result['added']} -{sync_result['removed']}")
    
    if LOW_MEMORY_MODE:
        print(f"üíæ Low-RAM: {CAMERA_WIDTH}x{CAMERA_HEIGHT}")
    
    if ENABLE_ADAPTIVE_SKIP:
        print(f"‚ö° Adaptive Skip: ON (target={int(TARGET_PROCESS_TIME*1000)}ms, range={MIN_FRAME_SKIP}-{MAX_FRAME_SKIP})")
    else:
        print(f"‚ö° Frame Skip: {DEFAULT_FRAME_SKIP} (fixed)")
    
    if ENABLE_MIDNIGHT_CHECKOUT:
        print(f"‚è∞ Auto Checkout: ON (00:00 m·ªói ng√†y)")

    # Log c∆° b·∫£n t·ª´ config ƒë·ªÉ x√°c nh·∫≠n
    logger.info(f"CONFIG: COOLDOWN={COOLDOWN_SECONDS}s, HOLD_TIME={HOLD_TIME_SECONDS}s, WEB={ENABLE_WEB_SERVER}:{WEB_PORT}, ANTISPOOF={ENABLE_ANTISPOOF}")
    
    if ENABLE_WEB_SERVER:
        import socket
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            local_ip = s.getsockname()[0]
            s.close()
        except:
            local_ip = "localhost"
        print(f"üåê Web: http://{local_ip}:{WEB_PORT}")
    
    print("-"*50)
    if not HEADLESS_MODE:
        print("‚å®Ô∏è  r=ƒëƒÉng k√Ω | d=x√≥a | l=list | q=tho√°t")
    else:
        print("‚å®Ô∏è  Ctrl+C ƒë·ªÉ tho√°t")
    print("="*50 + "\n")

    frame_count = 0
    last_status_time = 0
    last_midnight_check = datetime.datetime.now().date()  # Ng√†y cu·ªëi c√πng ƒë√£ ki·ªÉm tra midnight
    
    # Kh·ªüi t·∫°o Adaptive Frame Skip
    adaptive_skip = AdaptiveFrameSkip() if ENABLE_ADAPTIVE_SKIP else None
    
    # Ki·ªÉm tra midnight checkout ngay khi kh·ªüi ƒë·ªông (cho sessions t·ª´ h√¥m qua)
    if ENABLE_MIDNIGHT_CHECKOUT:
        auto_results = midnight_checkout_all_sessions()
        if auto_results:
            for r in auto_results:
                logger.warning(f"‚ö†Ô∏è Midnight checkout: {r['name']} ({r['duration_str']})")
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                logger.warning("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c camera!")
                break
            
            frame_count += 1
            current_time = time.time()
            
            # Ki·ªÉm tra midnight checkout khi sang ng√†y m·ªõi
            if ENABLE_MIDNIGHT_CHECKOUT:
                today = datetime.datetime.now().date()
                if today > last_midnight_check:
                    auto_results = midnight_checkout_all_sessions()
                    if auto_results:
                        for r in auto_results:
                            logger.warning(f"‚ö†Ô∏è Midnight checkout: {r['name']} ({r['duration_str']})")
                    last_midnight_check = today
            
            # Skip frames ƒë·ªÉ ti·∫øt ki·ªám CPU/RAM
            if ENABLE_ADAPTIVE_SKIP and adaptive_skip:
                should_process = adaptive_skip.should_process(frame_count)
            else:
                should_process = (frame_count % DEFAULT_FRAME_SKIP == 0)
            
            if not should_process:
                if not HEADLESS_MODE:
                    cv2.imshow("May Cham Cong", frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                continue
            
            # B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian x·ª≠ l√Ω
            process_start_time = time.time()
            
            # Garbage collection ƒë·ªãnh k·ª≥
            if frame_count % GC_INTERVAL == 0:
                gc.collect()

            # detection module nh·∫≠n BGR (chu·∫©n OpenCV)
            detections = detect_faces(frame)
            
            # Danh s√°ch ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán trong frame n√†y
            recognized_this_frame = set()

            for det in detections:
                x, y, w, h = det['box']
                
                # Validate k√≠ch th∆∞·ªõc: M·∫∑t qu√° nh·ªè (<60px) th√¨ b·ªè qua ƒë·ªÉ ƒë·ª° t·ªën CPU detect anti-spoof
                if w < 60 or h < 60:
                    continue

                face = frame[y:y+h, x:x+w]
                if face.size == 0: continue

                # --- B∆Ø·ªöC 1: Anti-Spoofing (c√≥ th·ªÉ t·∫Øt ƒë·ªÉ test) ---
                if ENABLE_ANTISPOOF and anti is not None:
                    is_real = anti.is_live(face)
                else:
                    is_real = True  # B·ªè qua anti-spoof
                
                # --- B∆Ø·ªöC 2: Recognition ---
                label, distance = recognizer.recognize(face, threshold=RECOGNITION_THRESHOLD)
                
                # Hi·ªÉn th·ªã distance ƒë·ªÉ debug
                dist_text = f"d={distance:.2f}" if distance < float('inf') else ""
                
                if not is_real:
                    # FAKE: M√†u ƒë·ªè
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
                    name_text = label if label else "Unknown"
                    cv2.putText(frame, f"FAKE - {name_text}", (x, y-10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                else:
                    # REAL: X·ª≠ l√Ω theo c√≥ nh·∫≠n di·ªán ƒë∆∞·ª£c hay kh√¥ng
                    if label is None:
                        # Ng∆∞·ªùi l·∫° (V√†ng) - ch∆∞a ƒëƒÉng k√Ω ho·∫∑c distance qu√° xa
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)
                        cv2.putText(frame, f"Unknown {dist_text}", (x, y-10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    else:
                        # Ng∆∞·ªùi quen (Xanh l√°) - ƒë√£ ƒëƒÉng k√Ω
                        recognized_this_frame.add(label)
                        current_time = time.time()
                        
                        # --- B∆Ø·ªöC 3: Logic gi·ªØ m·∫∑t ---
                        # N·∫øu ch∆∞a theo d√µi ng∆∞·ªùi n√†y, b·∫Øt ƒë·∫ßu theo d√µi
                        if label not in face_hold_tracker:
                            face_hold_tracker[label] = current_time
                        
                        # T√≠nh th·ªùi gian ƒë√£ gi·ªØ m·∫∑t
                        hold_duration = current_time - face_hold_tracker[label]
                        remaining = max(0, HOLD_TIME_SECONDS - hold_duration)
                        
                        # Hi·ªÉn th·ªã progress bar gi·ªØ m·∫∑t
                        progress = min(hold_duration / HOLD_TIME_SECONDS, 1.0)
                        bar_width = w
                        bar_height = 8
                        bar_y = y + h + 5
                        
                        # V·∫Ω khung v√† progress
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                        cv2.rectangle(frame, (x, bar_y), (x + bar_width, bar_y + bar_height), (100, 100, 100), -1)
                        cv2.rectangle(frame, (x, bar_y), (x + int(bar_width * progress), bar_y + bar_height), (0, 255, 0), -1)
                        
                        if remaining > 0:
                            # ƒêang ƒë·∫øm ng∆∞·ª£c
                            cv2.putText(frame, f"{label} - Giu {remaining:.1f}s", (x, y-10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                        else:
                            # ƒê·ªß th·ªùi gian gi·ªØ m·∫∑t -> Ch·∫•m c√¥ng
                            cv2.putText(frame, f"{label} {dist_text}", (x, y-10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                            
                            # --- B∆Ø·ªöC 4: Logic Ch·∫•m C√¥ng (Debounce) ---
                            if label not in last_checkin or (current_time - last_checkin[label] > COOLDOWN_SECONDS):
                                action = log_attendance(label)  # Returns 'check_in' or 'check_out'
                                last_checkin[label] = current_time
                                # X√≥a kh·ªèi tracker ƒë·ªÉ tr√°nh ch·∫•m c√¥ng l·∫°i ngay
                                # (s·∫Ω ƒë∆∞·ª£c th√™m l·∫°i n·∫øu ng∆∞·ªùi ƒë√≥ v·∫´n trong frame sau cooldown)
                                if label in face_hold_tracker:
                                    del face_hold_tracker[label]
                                
                                # Log ng·∫Øn g·ªçn
                                symbol = "üü¢" if action == 'check_in' else "üî¥"
                                logger.info(f"{symbol} {label} - {action.upper().replace('_', '-')}")
                                
                                if not HEADLESS_MODE:
                                    if action == 'check_in':
                                        cv2.putText(frame, "CHECK-IN OK", (10, 50), 
                                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)
                                    else:
                                        cv2.putText(frame, "CHECK-OUT OK", (10, 50), 
                                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 3)
            
            # X√≥a tracker c·ªßa nh·ªØng ng∆∞·ªùi kh√¥ng c√≤n trong frame
            faces_to_remove = [name for name in face_hold_tracker if name not in recognized_this_frame]
            for name in faces_to_remove:
                # Ch·ªâ x√≥a n·∫øu kh√¥ng trong cooldown
                if name not in last_checkin or (time.time() - last_checkin.get(name, 0) > COOLDOWN_SECONDS):
                    del face_hold_tracker[name]

            # --- C·∫¨P NH·∫¨T ADAPTIVE FRAME SKIP ---
            if ENABLE_ADAPTIVE_SKIP and adaptive_skip:
                process_time = time.time() - process_start_time
                adaptive_skip.update(process_time)

            # --- PH·∫¶N HI·ªÇN TH·ªä V√Ä ƒêI·ªÄU KHI·ªÇN ---
            if HEADLESS_MODE:
                # HEADLESS MODE (Pi): Log ƒë·ªãnh k·ª≥ m·ªói 5 ph√∫t
                current_time = time.time()
                if current_time - last_status_time > 300:  # 5 ph√∫t
                    # Th√™m th√¥ng tin adaptive skip v√†o log
                    if ENABLE_ADAPTIVE_SKIP and adaptive_skip:
                        stats = adaptive_skip.get_stats()
                        logger.info(f"‚ôªÔ∏è Running... Faces: {len(detections)}, Skip: {stats['current_skip']}, Avg: {stats['avg_process_ms']:.0f}ms")
                    else:
                        logger.info(f"‚ôªÔ∏è Running... Faces detected: {len(detections)}")
                    last_status_time = current_time
            else:
                # GUI MODE (Windows): Hi·ªÉn th·ªã c·ª≠a s·ªï camera v√† x·ª≠ l√Ω ph√≠m
                
                # Hi·ªÉn th·ªã th√¥ng tin Adaptive Skip tr√™n GUI
                if ENABLE_ADAPTIVE_SKIP and adaptive_skip:
                    stats = adaptive_skip.get_stats()
                    info_text = f"Skip:{stats['current_skip']} | {stats['avg_process_ms']:.0f}ms | ~{stats['effective_fps']:.1f}fps"
                    cv2.putText(frame, info_text, (10, frame.shape[0] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
                
                cv2.imshow("May Cham Cong", frame)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('l'):
                    # Hi·ªÉn th·ªã danh s√°ch ƒë√£ ƒëƒÉng k√Ω
                    print("\nüìã Database:")
                    names = recognizer.get_registered_names()
                    if names:
                        for i, name in enumerate(names, 1):
                            emb_count = len(recognizer.db[name]) if isinstance(recognizer.db[name], list) else 1
                            print(f"   {i}. {name} ({emb_count})")
                    else:
                        print("   (tr·ªëng)")
                    print()
                elif key == ord('d'):
                    # X√≥a ng∆∞·ªùi kh·ªèi database
                    cv2.destroyAllWindows()
                    print("\nüóëÔ∏è X√≥a ng∆∞·ªùi:")
                    names = recognizer.get_registered_names()
                    if not names:
                        print("   Database tr·ªëng!")
                    else:
                        for i, name in enumerate(names, 1):
                            print(f"   {i}. {name}")
                        choice = input("Nh·∫≠p t√™n (Enter=h·ªßy): ").strip()
                        if choice:
                            if recognizer.remove_face(choice):
                                recognizer.save_db()
                                remove_employee(choice)
                                print(f"   ‚úÖ ƒê√£ x√≥a: {choice}")
                            else:
                                print(f"   ‚ùå Kh√¥ng t√¨m th·∫•y: {choice}")
                    print()
                    cv2.namedWindow("May Cham Cong")
                elif key == ord('r'):
                    # ƒêƒÉng k√Ω khu√¥n m·∫∑t m·ªõi
                    if len(detections) > 0:
                        detections.sort(key=lambda d: d['box'][2] * d['box'][3], reverse=True)
                        det = detections[0]
                        x, y, w, h = det['box']
                        face_reg = frame[y:y+h, x:x+w]
                        
                        cv2.destroyAllWindows()
                        name = input("T√™n nh√¢n vi√™n: ").strip()
                        if name:
                            recognizer.add_face(name, face_reg)
                            recognizer.save_db()
                            add_employee(name)
                            print(f"   ‚úÖ ƒê√£ ƒëƒÉng k√Ω: {name}\n")
                        
                        cv2.namedWindow("May Cham Cong")
                    
    except KeyboardInterrupt:
        print("\nüõë ƒê√£ d·ª´ng (Ctrl+C)")
    finally:
        cap.release()
        if not HEADLESS_MODE:
            cv2.destroyAllWindows()
        print("üëã Bye!")

if __name__ == "__main__":
    main()