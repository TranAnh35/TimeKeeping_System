# src/main.py
import cv2
import time
import datetime
import os
import gc
import sys
import platform
import threading
from detect import detect_faces
from recognition import FaceRecognizer
from database import log_attendance, add_employee, remove_employee, sync_employees_with_face_db, init_db, get_current_status

# --- T·ª∞ ƒê·ªòNG PH√ÅT HI·ªÜN PLATFORM ---
IS_WINDOWS = platform.system() == "Windows"
IS_PI = platform.system() == "Linux" and os.path.exists("/proc/device-tree/model")

# --- C·∫§U H√åNH ---
COOLDOWN_SECONDS = 60  # Th·ªùi gian ch·ªù gi·ªØa 2 l·∫ßn ch·∫•m c√¥ng cho c√πng 1 ng∆∞·ªùi
HOLD_TIME_SECONDS = 2.0  # Th·ªùi gian gi·ªØ m·∫∑t trong camera tr∆∞·ªõc khi ch·∫•m c√¥ng (gi√¢y)
ENABLE_WEB_SERVER = True  # B·∫≠t/t·∫Øt web dashboard
WEB_PORT = 5000
ENABLE_ANTISPOOF = False  # T·∫°m t·∫Øt anti-spoof ƒë·ªÉ ti·∫øt ki·ªám RAM
RECOGNITION_THRESHOLD = 0.4  # Threshold cho recognition (c√†ng nh·ªè c√†ng ch·∫∑t)

# --- CH·∫æ ƒê·ªò HO·∫†T ƒê·ªòNG ---
# Windows: GUI mode (c√≥ c·ª≠a s·ªï camera, c√≥ th·ªÉ th√™m/x√≥a th√†nh vi√™n)
# Pi: Headless mode (kh√¥ng GUI, ch·ªâ ch·∫•m c√¥ng, qu·∫£n l√Ω qua web)
HEADLESS_MODE = not IS_WINDOWS  # T·ª± ƒë·ªông: Pi = headless, Windows = GUI

# --- C·∫§U H√åNH T·ªêI ∆ØU RAM (cho Pi 3) ---
LOW_MEMORY_MODE = IS_PI  # T·ª± ƒë·ªông b·∫≠t tr√™n Pi
CAMERA_WIDTH = 640 if not LOW_MEMORY_MODE else 320
CAMERA_HEIGHT = 480 if not LOW_MEMORY_MODE else 240
FRAME_SKIP = 1 if not LOW_MEMORY_MODE else 2
GC_INTERVAL = 30

def start_web_server():
    """Ch·∫°y web server trong thread ri√™ng"""
    try:
        from web_server import run_server
        run_server(host='0.0.0.0', port=WEB_PORT)
    except ImportError:
        print("[WARNING] Kh√¥ng t√¨m th·∫•y web_server.py, b·ªè qua web dashboard")
    except Exception as e:
        print(f"[WARNING] Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông web server: {e}")

def main():
    # 0. Kh·ªüi t·∫°o Database
    init_db()
    
    # 0.1 Kh·ªüi ƒë·ªông Web Server (ch·∫°y n·ªÅn)
    if ENABLE_WEB_SERVER:
        web_thread = threading.Thread(target=start_web_server, daemon=True)
        web_thread.start()
    
    # 1. Kh·ªüi t·∫°o Camera v√† Models
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    # Gi·∫£m buffer size ƒë·ªÉ ti·∫øt ki·ªám RAM
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

    try:
        # Lazy loading: Ch·ªâ load AntiSpoof n·∫øu c·∫ßn
        anti = None
        if ENABLE_ANTISPOOF:
            from antispoof import AntiSpoof
            anti = AntiSpoof()
        
        recognizer = FaceRecognizer()
        
        # ƒê·ªìng b·ªô SQLite employees v·ªõi face_db.pkl
        sync_employees_with_face_db(recognizer.get_registered_names())
        
        # Garbage collect sau khi load xong models
        gc.collect()
        
    except Exception as e:
        print(f"L·ªói kh·ªüi t·∫°o Model: {e}")
        return

    # Dictionary l∆∞u th·ªùi gian ch·∫•m c√¥ng g·∫ßn nh·∫•t: { 'Ten_NV': time_float }
    last_checkin = {} 
    
    # Dictionary theo d√µi th·ªùi gian gi·ªØ m·∫∑t: { 'Ten_NV': first_seen_time }
    face_hold_tracker = {}

    print("H·ªá th·ªëng ch·∫•m c√¥ng s·∫µn s√†ng!")
    print(f"üìç Platform: {'Windows (GUI Mode)' if IS_WINDOWS else 'Raspberry Pi (Headless Mode)'}")
    print(f"‚è±Ô∏è  Gi·ªØ m·∫∑t trong camera {HOLD_TIME_SECONDS}s ƒë·ªÉ ch·∫•m c√¥ng.")
    if LOW_MEMORY_MODE:
        print(f"üíæ Ch·∫ø ƒë·ªô ti·∫øt ki·ªám RAM: {CAMERA_WIDTH}x{CAMERA_HEIGHT}, skip {FRAME_SKIP} frame(s)")
    
    if not HEADLESS_MODE:
        print("\nüñ•Ô∏è  CH·∫æ ƒê·ªò DEBUG (Windows):")
        print("   Nh·∫•n 'r' ƒë·ªÉ ƒëƒÉng k√Ω khu√¥n m·∫∑t m·ªõi.")
        print("   Nh·∫•n 'd' ƒë·ªÉ x√≥a ng∆∞·ªùi kh·ªèi database.")
        print("   Nh·∫•n 'l' ƒë·ªÉ xem danh s√°ch ƒë√£ ƒëƒÉng k√Ω.")
        print("   Nh·∫•n 'q' ƒë·ªÉ tho√°t.")
    else:
        print("\nü§ñ CH·∫æ ƒê·ªò HEADLESS (Pi):")
        print("   Qu·∫£n l√Ω th√†nh vi√™n qua Web Dashboard")
        print("   Nh·∫•n Ctrl+C ƒë·ªÉ tho√°t.")
    
    if ENABLE_WEB_SERVER:
        import socket
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            local_ip = s.getsockname()[0]
            s.close()
        except:
            local_ip = "localhost"
        print(f"\nüåê Web Dashboard:")
        print(f"   üì± T·ª´ ƒëi·ªán tho·∫°i: http://{local_ip}:{WEB_PORT}")
        print(f"   üíª Local: http://localhost:{WEB_PORT}\n")

    frame_count = 0
    last_status_time = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c camera!")
                break
            
            frame_count += 1
            
            # Skip frames ƒë·ªÉ ti·∫øt ki·ªám CPU/RAM
            if frame_count % FRAME_SKIP != 0:
                if not HEADLESS_MODE:
                    cv2.imshow("May Cham Cong", frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                continue
            
            # Garbage collection ƒë·ªãnh k·ª≥
            if frame_count % GC_INTERVAL == 0:
                gc.collect()

            # detection module nh·∫≠n BGR (chu·∫©n OpenCV)
            detections = detect_faces(frame)
            
            # Danh s√°ch ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán trong frame n√†y
            recognized_this_frame = set()

            for det in detections:
                x, y, w, h = det['box']
                
                # Validate k√≠ch th∆∞·ªõc: M·∫∑t qu√° nh·ªè (<60px) th√¨ b·ªè qua ƒë·ªÉ ƒë·ª° t·ªën CPU detect anti-spoof
                if w < 60 or h < 60:
                    continue

                face = frame[y:y+h, x:x+w]
                if face.size == 0: continue

                # --- B∆Ø·ªöC 1: Anti-Spoofing (c√≥ th·ªÉ t·∫Øt ƒë·ªÉ test) ---
                if ENABLE_ANTISPOOF and anti is not None:
                    is_real = anti.is_live(face)
                else:
                    is_real = True  # B·ªè qua anti-spoof
                
                # --- B∆Ø·ªöC 2: Recognition ---
                label, distance = recognizer.recognize(face, threshold=RECOGNITION_THRESHOLD)
                
                # Hi·ªÉn th·ªã distance ƒë·ªÉ debug
                dist_text = f"d={distance:.2f}" if distance < float('inf') else ""
                
                if not is_real:
                    # FAKE: M√†u ƒë·ªè
                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)
                    name_text = label if label else "Unknown"
                    cv2.putText(frame, f"FAKE - {name_text}", (x, y-10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                else:
                    # REAL: X·ª≠ l√Ω theo c√≥ nh·∫≠n di·ªán ƒë∆∞·ª£c hay kh√¥ng
                    if label is None:
                        # Ng∆∞·ªùi l·∫° (V√†ng) - ch∆∞a ƒëƒÉng k√Ω ho·∫∑c distance qu√° xa
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)
                        cv2.putText(frame, f"Unknown {dist_text}", (x, y-10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                    else:
                        # Ng∆∞·ªùi quen (Xanh l√°) - ƒë√£ ƒëƒÉng k√Ω
                        recognized_this_frame.add(label)
                        current_time = time.time()
                        
                        # --- B∆Ø·ªöC 3: Logic gi·ªØ m·∫∑t ---
                        # N·∫øu ch∆∞a theo d√µi ng∆∞·ªùi n√†y, b·∫Øt ƒë·∫ßu theo d√µi
                        if label not in face_hold_tracker:
                            face_hold_tracker[label] = current_time
                        
                        # T√≠nh th·ªùi gian ƒë√£ gi·ªØ m·∫∑t
                        hold_duration = current_time - face_hold_tracker[label]
                        remaining = max(0, HOLD_TIME_SECONDS - hold_duration)
                        
                        # Hi·ªÉn th·ªã progress bar gi·ªØ m·∫∑t
                        progress = min(hold_duration / HOLD_TIME_SECONDS, 1.0)
                        bar_width = w
                        bar_height = 8
                        bar_y = y + h + 5
                        
                        # V·∫Ω khung v√† progress
                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                        cv2.rectangle(frame, (x, bar_y), (x + bar_width, bar_y + bar_height), (100, 100, 100), -1)
                        cv2.rectangle(frame, (x, bar_y), (x + int(bar_width * progress), bar_y + bar_height), (0, 255, 0), -1)
                        
                        if remaining > 0:
                            # ƒêang ƒë·∫øm ng∆∞·ª£c
                            cv2.putText(frame, f"{label} - Giu {remaining:.1f}s", (x, y-10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                        else:
                            # ƒê·ªß th·ªùi gian gi·ªØ m·∫∑t -> Ch·∫•m c√¥ng
                            cv2.putText(frame, f"{label} {dist_text}", (x, y-10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                            
                            # --- B∆Ø·ªöC 4: Logic Ch·∫•m C√¥ng (Debounce) ---
                            if label not in last_checkin or (current_time - last_checkin[label] > COOLDOWN_SECONDS):
                                action = log_attendance(label)  # Returns 'check_in' or 'check_out'
                                last_checkin[label] = current_time
                                # Reset tracker sau khi ch·∫•m c√¥ng
                                face_hold_tracker[label] = current_time + COOLDOWN_SECONDS
                                
                                # Log ra console (cho c·∫£ headless mode)
                                action_text = "CHECK-IN" if action == 'check_in' else "CHECK-OUT"
                                print(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ‚úÖ {action_text}: {label}")
                                
                                if not HEADLESS_MODE:
                                    if action == 'check_in':
                                        cv2.putText(frame, "CHECK-IN OK", (10, 50), 
                                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)
                                    else:
                                        cv2.putText(frame, "CHECK-OUT OK", (10, 50), 
                                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 3)
            
            # X√≥a tracker c·ªßa nh·ªØng ng∆∞·ªùi kh√¥ng c√≤n trong frame
            faces_to_remove = [name for name in face_hold_tracker if name not in recognized_this_frame]
            for name in faces_to_remove:
                # Ch·ªâ x√≥a n·∫øu kh√¥ng trong cooldown
                if name not in last_checkin or (time.time() - last_checkin.get(name, 0) > COOLDOWN_SECONDS):
                    del face_hold_tracker[name]

            # --- PH·∫¶N HI·ªÇN TH·ªä V√Ä ƒêI·ªÄU KHI·ªÇN ---
            if HEADLESS_MODE:
                # HEADLESS MODE (Pi): Kh√¥ng hi·ªÉn th·ªã GUI, ch·ªâ log ra console ƒë·ªãnh k·ª≥
                current_time = time.time()
                if current_time - last_status_time > 60:  # Log m·ªói 60 gi√¢y
                    print(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] ƒêang ch·∫°y... Frame: {frame_count}")
                    last_status_time = current_time
            else:
                # GUI MODE (Windows): Hi·ªÉn th·ªã c·ª≠a s·ªï camera v√† x·ª≠ l√Ω ph√≠m
                cv2.imshow("May Cham Cong", frame)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('l'):
                    # Hi·ªÉn th·ªã danh s√°ch ƒë√£ ƒëƒÉng k√Ω
                    print("\n" + "="*40)
                    print("üìã DANH S√ÅCH ƒê√É ƒêƒÇNG K√ù:")
                    print("="*40)
                    names = recognizer.get_registered_names()
                    if names:
                        for i, name in enumerate(names, 1):
                            emb_count = len(recognizer.db[name]) if isinstance(recognizer.db[name], list) else 1
                            print(f"  {i}. {name} ({emb_count} ·∫£nh)")
                    else:
                        print("  (Ch∆∞a c√≥ ai ƒëƒÉng k√Ω)")
                    print("="*40 + "\n")
                elif key == ord('d'):
                    # X√≥a ng∆∞·ªùi kh·ªèi database
                    cv2.destroyAllWindows()
                    print("\n" + "="*40)
                    print("üóëÔ∏è  X√ìA NG∆Ø·ªúI KH·ªéI DATABASE")
                    print("="*40)
                    names = recognizer.get_registered_names()
                    if not names:
                        print("Database tr·ªëng, kh√¥ng c√≥ g√¨ ƒë·ªÉ x√≥a!")
                    else:
                        print("Danh s√°ch hi·ªán c√≥:")
                        for i, name in enumerate(names, 1):
                            emb_count = len(recognizer.db[name]) if isinstance(recognizer.db[name], list) else 1
                            print(f"  {i}. {name} ({emb_count} ·∫£nh)")
                        print("-"*40)
                        choice = input("Nh·∫≠p t√™n c·∫ßn x√≥a (ho·∫∑c Enter ƒë·ªÉ h·ªßy): ").strip()
                        if choice:
                            if recognizer.remove_face(choice):
                                recognizer.save_db()
                                remove_employee(choice)  # X√≥a kh·ªèi SQLite database
                                print(f"‚úÖ ƒê√£ x√≥a '{choice}' kh·ªèi database!")
                            else:
                                print(f"‚ùå Kh√¥ng t√¨m th·∫•y '{choice}' trong database!")
                        else:
                            print("ƒê√£ h·ªßy.")
                    print("="*40 + "\n")
                    cv2.namedWindow("May Cham Cong")
                elif key == ord('r'):
                    # Logic ƒëƒÉng k√Ω ƒë∆°n gi·∫£n (l·∫•y khu√¥n m·∫∑t to nh·∫•t trong khung h√¨nh)
                    if len(detections) > 0:
                        # S·∫Øp x·∫øp l·∫•y box to nh·∫•t (di·ªán t√≠ch w*h)
                        detections.sort(key=lambda d: d['box'][2] * d['box'][3], reverse=True)
                        
                        det = detections[0]
                        x, y, w, h = det['box']
                        face_reg = frame[y:y+h, x:x+w]
                        
                        cv2.destroyAllWindows()
                        name = input("Nhap ten nhan vien moi: ")
                        if name:
                            recognizer.add_face(name, face_reg)
                            recognizer.save_db()
                            add_employee(name)
                            print(f"Da dang ky thanh cong: {name}")
                        
                        cv2.namedWindow("May Cham Cong")
                    
    except KeyboardInterrupt:
        print("\n\nüõë ƒê√£ d·ª´ng b·ªüi ng∆∞·ªùi d√πng (Ctrl+C)")
    finally:
        cap.release()
        if not HEADLESS_MODE:
            cv2.destroyAllWindows()
        print("üëã T·∫°m bi·ªát!")

if __name__ == "__main__":
    main()